<!doctype html>
<html class="no-js" lang="en" data-content_root="./">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="Decorators" href="decorators.html" /><link rel="prev" title="Neural Networks" href="nets.html" />

    <link rel="shortcut icon" href="_static/favicon.ico"/><!-- Generated with Sphinx 8.1.3 and Furo 2024.08.06 -->
        <title>Lightning implementation - CNN Project</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=8775fe07" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=302659d7" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: #4d4d4d;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #C9FFEE;
  --color-brand-content: #00FF6A;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #C9FFEE;
  --color-brand-content: #00FF6A;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>

<div class="announcement">
  <aside class="announcement-content">
     Welcome to CNN Project's documentation! 
  </aside>
</div>

<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">CNN Project</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  
  <span class="sidebar-brand-text">CNN Project</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="defs.html">Base Classes and Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasets.html">Dataset Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="nets.html">Neural Networks</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Lightning implementation</a></li>
<li class="toctree-l1"><a class="reference internal" href="decorators.html">Decorators</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="_sources/lightning_objects.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="lightning-implementation">
<h1>Lightning implementation<a class="headerlink" href="#lightning-implementation" title="Link to this heading">¶</a></h1>
<p>To train a lightning model (more specifically a <a class="reference internal" href="#lightning_objects.LitConvNet" title="lightning_objects.LitConvNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">LitConvNet</span></code></a> object),
the <a class="reference internal" href="#lightning_objects.train_lightning_model" title="lightning_objects.train_lightning_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">train_lightning_model()</span></code></a> function must be used. It is necessary to
pass a DataLoader tuple with the training and validation DataLoaders, as well as a configuration
dictionary.</p>
<p>The configuration dictionary contains information about the model itself (“model” entry), as well as the
training (“training” entry). It also allow specification of keyword arguments to lightning’s <a class="reference external" href="https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.trainer.trainer.Trainer.html#trainer">lightning.pytorch.Trainer</a>,
(through the “training.trainer_kwargs”). An example of a commented config dictionary is given below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
   <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="mi">74</span><span class="p">,</span> <span class="c1"># Seed passed to lightning&#39;s &quot;seed_everything&quot;.</span>
   <span class="s2">&quot;comment&quot;</span><span class="p">:</span> <span class="s2">&quot;First lightning test!&quot;</span><span class="p">,</span> <span class="c1"># A comment to add to the model report</span>
      <span class="c1"># (this is done on_fit_start(), through training.TrainingClass.add_training()).</span>
   <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="s2">&quot;fourlayer&quot;</span><span class="p">,</span> <span class="c1"># The name of the PyTorch model.</span>
         <span class="c1"># See LitConvNet&#39;s class attribute &quot;model_dict&quot; for possible values.</span>
      <span class="s2">&quot;model_args&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="c1"># *args passed to the PyTorch model initialization.</span>
      <span class="s2">&quot;model_kwargs&quot;</span><span class="p">:</span> <span class="p">{</span> <span class="c1"># **kwargs passed to the PyTorch model initialization.</span>
         <span class="s2">&quot;dirname&quot;</span><span class="p">:</span> <span class="s2">&quot;FourLayer_lightning_test&quot;</span>
      <span class="p">}</span>
   <span class="p">},</span>
   <span class="s2">&quot;training&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;loss_fn&quot;</span><span class="p">:</span> <span class="s2">&quot;NLLLoss&quot;</span><span class="p">,</span> <span class="c1"># Name of the loss function to be used.</span>
         <span class="c1"># must be the name of a function defined in the torch.nn module.</span>
         <span class="c1"># We&#39;ll fetch it using getattr(torch.nn, config[&quot;training&quot;][&quot;loss_fn&quot;])</span>
      <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="c1"># See training.NetBase.get_params().</span>
      <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
      <span class="s2">&quot;trainer_kwargs&quot;</span><span class="p">:</span> <span class="p">{</span>
         <span class="c1"># kwargs passed directly to lightning&#39;s Trainer class</span>
         <span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
         <span class="s2">&quot;limit_train_batches&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
         <span class="s2">&quot;limit_val_batches&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
         <span class="s2">&quot;accelerator&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
         <span class="s2">&quot;deterministic&quot;</span><span class="p">:</span> <span class="kc">True</span>

      <span class="p">},</span>
<span class="w">      </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">      fit_kwargs: {</span>
<span class="sd">         &#39;ckpt_path&#39; can be specified for loading a checkpoint. See train_lightning_model&#39;s</span>
<span class="sd">         docstring.</span>
<span class="sd">         &#39;ckpt_path&#39;: path_to_checkpoint</span>
<span class="sd">      }</span>
<span class="sd">      &quot;&quot;&quot;</span>
      <span class="s2">&quot;finish_training_kwargs&quot;</span><span class="p">:</span> <span class="p">{</span>
         <span class="c1"># kwargs passed to training.TrainingClass.finish_training()</span>
         <span class="c1"># at the end of training.</span>
         <span class="s2">&quot;remove_bool&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
         <span class="s2">&quot;plot_accuracy&quot;</span><span class="p">:</span> <span class="kc">True</span>
      <span class="p">}</span>
   <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Note that some of the documentation for <a class="reference internal" href="#lightning_objects.LitConvNet" title="lightning_objects.LitConvNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">LitConvNet</span></code></a> comes directly from Lightning’s
documentation (specifically, for <a class="reference internal" href="#lightning_objects.LitConvNet.configure_optimizers" title="lightning_objects.LitConvNet.configure_optimizers"><code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_optimizers()</span></code></a>,
<a class="reference internal" href="#lightning_objects.LitConvNet.forward" title="lightning_objects.LitConvNet.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a>, <a class="reference internal" href="#lightning_objects.LitConvNet.training_step" title="lightning_objects.LitConvNet.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>,
<a class="reference internal" href="#lightning_objects.LitConvNet.on_train_epoch_end" title="lightning_objects.LitConvNet.on_train_epoch_end"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_train_epoch_end()</span></code></a>, <a class="reference internal" href="#lightning_objects.LitConvNet.validation_step" title="lightning_objects.LitConvNet.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a>,
<a class="reference internal" href="#lightning_objects.LitConvNet.on_validation_epoch_end" title="lightning_objects.LitConvNet.on_validation_epoch_end"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_validation_epoch_end()</span></code></a>). Lightning functions
which have custom documentation are noted with “[Custom documentation]” at the beginning of its
docstring.</p>
<p>Note that, since <a class="reference internal" href="#lightning_objects.LitConvNet" title="lightning_objects.LitConvNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">LitConvNet</span></code></a> is just a wrapper to a <a class="reference internal" href="nets.html#nets.ConvNetBase" title="nets.ConvNetBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConvNetBase</span></code></a>, it
also contains <a class="reference internal" href="defs.html#training.TrainingClass" title="training.TrainingClass"><code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingClass</span></code></a> (dealt with in <a class="reference internal" href="#lightning_objects.LitConvNet.on_train_epoch_end" title="lightning_objects.LitConvNet.on_train_epoch_end"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_train_epoch_end()</span></code></a>,
<a class="reference internal" href="#lightning_objects.LitConvNet.on_validation_epoch_end" title="lightning_objects.LitConvNet.on_validation_epoch_end"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_validation_epoch_end()</span></code></a> and <a class="reference internal" href="#lightning_objects.LitConvNet.on_fit_end" title="lightning_objects.LitConvNet.on_fit_end"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_fit_end()</span></code></a>)
and <a class="reference internal" href="defs.html#training.ReportManager" title="training.ReportManager"><code class="xref py py-class docutils literal notranslate"><span class="pre">ReportManager</span></code></a> classes. These classes can also be directly accessed by the
property attributes <code class="docutils literal notranslate"><span class="pre">manager</span></code> and <code class="docutils literal notranslate"><span class="pre">trainclass</span></code>.</p>
<dl class="py function" id="module-lightning_objects">
<dt class="sig sig-object py" id="lightning_objects.train_lightning_model">
<span class="sig-prename descclassname"><span class="pre">lightning_objects.</span></span><span class="sig-name descname"><span class="pre">train_lightning_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loader_tuple</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightning_objects.html#train_lightning_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lightning_objects.train_lightning_model" title="Link to this definition">¶</a></dt>
<dd><p>Function for training a Lightning model (more specifically a
<a class="reference internal" href="#lightning_objects.LitConvNet" title="lightning_objects.LitConvNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">LitConvNet</span></code></a> model).</p>
<p>There are two possible ways of loading a pre-existing model:</p>
<ul class="simple">
<li><p>By loading the <code class="docutils literal notranslate"><span class="pre">best_model.pkl</span></code>: if the user specified the
directory of the model’s report with
<code class="docutils literal notranslate"><span class="pre">config[&quot;training&quot;][&quot;trainer_kwargs&quot;][&quot;default_root_dir&quot;]</span></code>.
Note that this is preferable as it will also load the <a class="reference internal" href="defs.html#training.TrainingClass" title="training.TrainingClass"><code class="xref py py-class docutils literal notranslate"><span class="pre">TrainingClass</span></code></a>
and <a class="reference internal" href="defs.html#training.ReportManager" title="training.ReportManager"><code class="xref py py-class docutils literal notranslate"><span class="pre">ReportManager</span></code></a> classes in their latest state,
instead of recreating them from scratch.</p></li>
<li><p>By loading a lightning checkpoint: if the user specified its
path through the config entry
<code class="docutils literal notranslate"><span class="pre">config[&quot;training&quot;][&quot;fit_kwargs&quot;][&quot;ckpt_path&quot;]</span></code>.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If both options are specified in the config file,
both the best model will be loaded and its checkpoints.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> – The config dictionary from which defined training and model
hyperparameters.</p></li>
<li><p><strong>loader_tuple</strong> – A tuple with two torch.utils.data.DataLoader objects:
for training and validation respectively.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="lightning_objects.get_trainer">
<span class="sig-prename descclassname"><span class="pre">lightning_objects.</span></span><span class="sig-name descname"><span class="pre">get_trainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">user_trainer_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightning_objects.html#get_trainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lightning_objects.get_trainer" title="Link to this definition">¶</a></dt>
<dd><p>Returns lightning’s trainer object according to user-defined kwargs.
Some default kwargs are defined in this function.</p>
<dl class="field-list simple">
<dt class="field-odd">Keyword Arguments<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**user_trainer_kwargs</strong> – Any kwargs that can be passed to Lightning’s
lightning.pytorch.Trainer object. Only one default kwarg is specified:
<code class="docutils literal notranslate"><span class="pre">deterministic</span> <span class="pre">=</span> <span class="pre">True</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lightning_objects.</span></span><span class="sig-name descname"><span class="pre">LitConvNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightning_objects.html#LitConvNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lightning_objects.LitConvNet" title="Link to this definition">¶</a></dt>
<dd><p>Generic LightningModule wrapping Pytorch models defined in <a class="reference internal" href="nets.html#module-nets" title="nets"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nets</span></code></a>.</p>
<dl>
<dt>Class Attributes:</dt><dd><dl>
<dt>model_dict: dictionary relating names to the pytorch models defined in <a class="reference internal" href="nets.html#module-nets" title="nets"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nets</span></code></a>. Must</dt><dd><p>be updated if new models are added.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dictionary of available model names:</span>
<span class="n">model_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;twolayer&quot;</span><span class="p">:</span>   <span class="n">TwoLayer</span><span class="p">,</span>
    <span class="s2">&quot;threelayer&quot;</span><span class="p">:</span> <span class="n">ThreeLayer</span><span class="p">,</span>
    <span class="s2">&quot;fourlayer&quot;</span><span class="p">:</span>  <span class="n">FourLayer</span><span class="p">,</span>
    <span class="s2">&quot;tfcnn&quot;</span><span class="p">:</span>      <span class="n">TFCNN</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>config</strong> – a dictionary containing all information required for model initialization and training.
See the example at the top of the page.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.config">
<span class="sig-name descname"><span class="pre">config</span></span><a class="headerlink" href="#lightning_objects.LitConvNet.config" title="Link to this definition">¶</a></dt>
<dd><p>the config passed for <code class="docutils literal notranslate"><span class="pre">__init__</span></code>.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.model_config">
<span class="sig-name descname"><span class="pre">model_config</span></span><a class="headerlink" href="#lightning_objects.LitConvNet.model_config" title="Link to this definition">¶</a></dt>
<dd><p>the <code class="docutils literal notranslate"><span class="pre">&quot;model&quot;</span></code> entry of the config.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.training_config">
<span class="sig-name descname"><span class="pre">training_config</span></span><a class="headerlink" href="#lightning_objects.LitConvNet.training_config" title="Link to this definition">¶</a></dt>
<dd><p>the <code class="docutils literal notranslate"><span class="pre">&quot;training&quot;</span></code> entry of the config.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.model">
<span class="sig-name descname"><span class="pre">model</span></span><a class="headerlink" href="#lightning_objects.LitConvNet.model" title="Link to this definition">¶</a></dt>
<dd><p>the actual PyTorch model (one of the models defined in <a class="reference internal" href="nets.html#module-nets" title="nets"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nets</span></code></a>).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.loss">
<span class="sig-name descname"><span class="pre">loss</span></span><a class="headerlink" href="#lightning_objects.LitConvNet.loss" title="Link to this definition">¶</a></dt>
<dd><p>a <code class="docutils literal notranslate"><span class="pre">torch.nn</span></code> loss function, used for calculating the loss metrirc.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.train_step_loss">
<span class="sig-name descname"><span class="pre">train_step_loss</span></span><a class="headerlink" href="#lightning_objects.LitConvNet.train_step_loss" title="Link to this definition">¶</a></dt>
<dd><p>a list containing each training step’s loss. Cleared at the end of the epoch.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.valid_step_loss">
<span class="sig-name descname"><span class="pre">valid_step_loss</span></span><a class="headerlink" href="#lightning_objects.LitConvNet.valid_step_loss" title="Link to this definition">¶</a></dt>
<dd><p>a list containing each validation step’s loss. Cleared at the end of the epoch.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.train_step_accur">
<span class="sig-name descname"><span class="pre">train_step_accur</span></span><a class="headerlink" href="#lightning_objects.LitConvNet.train_step_accur" title="Link to this definition">¶</a></dt>
<dd><p>a list containing each training step’s accuracy. Cleared at the end of the epoch.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.valid_step_accur">
<span class="sig-name descname"><span class="pre">valid_step_accur</span></span><a class="headerlink" href="#lightning_objects.LitConvNet.valid_step_accur" title="Link to this definition">¶</a></dt>
<dd><p>a list containing each validation step’s accuracy. Cleared at the end of the epoch.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lightning_objects.html#LitConvNet.configure_optimizers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lightning_objects.LitConvNet.configure_optimizers" title="Link to this definition">¶</a></dt>
<dd><p>Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you’d need one.
But in the case of GANs or similar you might have multiple. Optimization with multiple optimizers only works in
the manual optimization mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><p>Any of these 6 options.</p>
<ul class="simple">
<li><p><strong>Single optimizer</strong>.</p></li>
<li><p><strong>List or Tuple</strong> of optimizers.</p></li>
<li><p><strong>Two lists</strong> - The first list has multiple optimizers, and the second has multiple LR schedulers
(or multiple <code class="docutils literal notranslate"><span class="pre">lr_scheduler_config</span></code>).</p></li>
<li><p><strong>Dictionary</strong>, with an <code class="docutils literal notranslate"><span class="pre">&quot;optimizer&quot;</span></code> key, and (optionally) a <code class="docutils literal notranslate"><span class="pre">&quot;lr_scheduler&quot;</span></code>
key whose value is a single LR scheduler or <code class="docutils literal notranslate"><span class="pre">lr_scheduler_config</span></code>.</p></li>
<li><p><strong>None</strong> - Fit will run without any optimizer.</p></li>
</ul>
</p>
</dd>
</dl>
<p>The <code class="docutils literal notranslate"><span class="pre">lr_scheduler_config</span></code> is a dictionary which contains the scheduler and its associated configuration.
The default configuration is shown below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lr_scheduler_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># REQUIRED: The scheduler instance</span>
    <span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="n">lr_scheduler</span><span class="p">,</span>
    <span class="c1"># The unit of the scheduler&#39;s step size, could also be &#39;step&#39;.</span>
    <span class="c1"># &#39;epoch&#39; updates the scheduler on epoch end whereas &#39;step&#39;</span>
    <span class="c1"># updates it after a optimizer update.</span>
    <span class="s2">&quot;interval&quot;</span><span class="p">:</span> <span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="c1"># How many epochs/steps should pass between calls to</span>
    <span class="c1"># `scheduler.step()`. 1 corresponds to updating the learning</span>
    <span class="c1"># rate after every epoch/step.</span>
    <span class="s2">&quot;frequency&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="c1"># Metric to to monitor for schedulers like `ReduceLROnPlateau`</span>
    <span class="s2">&quot;monitor&quot;</span><span class="p">:</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
    <span class="c1"># If set to `True`, will enforce that the value specified &#39;monitor&#39;</span>
    <span class="c1"># is available when the scheduler is updated, thus stopping</span>
    <span class="c1"># training if not found. If set to `False`, it will only produce a warning</span>
    <span class="s2">&quot;strict&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="c1"># If using the `LearningRateMonitor` callback to monitor the</span>
    <span class="c1"># learning rate progress, this keyword can be used to specify</span>
    <span class="c1"># a custom logged name</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>When there are schedulers in which the <code class="docutils literal notranslate"><span class="pre">.step()</span></code> method is conditioned on a value, such as the
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.lr_scheduler.ReduceLROnPlateau</span></code> scheduler, Lightning requires that the
<code class="docutils literal notranslate"><span class="pre">lr_scheduler_config</span></code> contains the keyword <code class="docutils literal notranslate"><span class="pre">&quot;monitor&quot;</span></code> set to the metric name that the scheduler
should be conditioned on.</p>
<p>Metrics can be made available to monitor by simply logging it using
<code class="docutils literal notranslate"><span class="pre">self.log('metric_to_track',</span> <span class="pre">metric_val)</span></code> in your <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Some things to know:</p>
<ul class="simple">
<li><p>Lightning calls <code class="docutils literal notranslate"><span class="pre">.backward()</span></code> and <code class="docutils literal notranslate"><span class="pre">.step()</span></code> automatically in case of automatic optimization.</p></li>
<li><p>If a learning rate scheduler is specified in <code class="docutils literal notranslate"><span class="pre">configure_optimizers()</span></code> with key
<code class="docutils literal notranslate"><span class="pre">&quot;interval&quot;</span></code> (default “epoch”) in the scheduler configuration, Lightning will call
the scheduler’s <code class="docutils literal notranslate"><span class="pre">.step()</span></code> method automatically in case of automatic optimization.</p></li>
<li><p>If you use 16-bit precision (<code class="docutils literal notranslate"><span class="pre">precision=16</span></code>), Lightning will automatically handle the optimizer.</p></li>
<li><p>If you use <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.LBFGS</span></code>, Lightning handles the closure function automatically for you.</p></li>
<li><p>If you use multiple optimizers, you will have to switch to ‘manual optimization’ mode and step them
yourself.</p></li>
<li><p>If you need to control how often the optimizer steps, override the <code class="xref py py-meth docutils literal notranslate"><span class="pre">optimizer_step()</span></code> hook.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/lightning_objects.html#LitConvNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lightning_objects.LitConvNet.forward" title="Link to this definition">¶</a></dt>
<dd><p>Same as <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.forward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – Whatever you decide to pass into the forward method.</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments are also possible.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Your model’s output</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.on_fit_start">
<span class="sig-name descname"><span class="pre">on_fit_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/lightning_objects.html#LitConvNet.on_fit_start"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lightning_objects.LitConvNet.on_fit_start" title="Link to this definition">¶</a></dt>
<dd><p>[Custom documentation] Does some reporting with the model <code class="xref py py-class docutils literal notranslate"><span class="pre">TrainClass</span></code>
<code class="xref py py-meth docutils literal notranslate"><span class="pre">add_training()</span></code> method. If it is the model’s first
fit, then a ModelReport.txt is also created.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/lightning_objects.html#LitConvNet.training_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lightning_objects.LitConvNet.training_step" title="Link to this definition">¶</a></dt>
<dd><p>Here you compute and return the training loss and some additional metrics for e.g. the progress bar or
logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – The output of your data iterable, normally a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
<li><p><strong>batch_idx</strong> – The index of this batch.</p></li>
<li><p><strong>dataloader_idx</strong> – The index of the dataloader that produced this batch.
(only if multiple dataloaders used)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> - The loss tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - A dictionary which can include any keys, but must include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code> in the case of
automatic optimization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - In automatic optimization, this will skip to the next batch (but is not supported for
multi-GPU, TPU, or DeepSpeed). For manual optimization, this has no special meaning, as returning
the loss is not required.</p></li>
</ul>
</p>
</dd>
</dl>
<p>In this step you’d normally do the forward pass and calculate the loss for a batch.
You can also do fancier things like multiple forward passes or something model specific.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
<p>To use multiple optimizers, you can switch to ‘manual optimization’ and control their stepping:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">automatic_optimization</span> <span class="o">=</span> <span class="kc">False</span>


<span class="c1"># Multiple optimizers (e.g.: GANs)</span>
<span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">opt1</span><span class="p">,</span> <span class="n">opt2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>

    <span class="c1"># do training_step with encoder</span>
    <span class="o">...</span>
    <span class="n">opt1</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="c1"># do training_step with decoder</span>
    <span class="o">...</span>
    <span class="n">opt2</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When <code class="docutils literal notranslate"><span class="pre">accumulate_grad_batches</span></code> &gt; 1, the loss returned here will be automatically
normalized by <code class="docutils literal notranslate"><span class="pre">accumulate_grad_batches</span></code> internally.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.on_train_epoch_end">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/lightning_objects.html#LitConvNet.on_train_epoch_end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lightning_objects.LitConvNet.on_train_epoch_end" title="Link to this definition">¶</a></dt>
<dd><p>Called in the training loop at the very end of the epoch.</p>
<p>To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> and access them in this hook:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyLightningModule</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># do something with all training_step outputs, for example:</span>
        <span class="n">epoch_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;training_epoch_mean&quot;</span><span class="p">,</span> <span class="n">epoch_mean</span><span class="p">)</span>
        <span class="c1"># free up the memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/lightning_objects.html#LitConvNet.validation_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lightning_objects.LitConvNet.validation_step" title="Link to this definition">¶</a></dt>
<dd><p>Operates on a single batch of data from the validation set. In this step you’d might generate examples or
calculate anything of interest like accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – The output of your data iterable, normally a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
<li><p><strong>batch_idx</strong> – The index of this batch.</p></li>
<li><p><strong>dataloader_idx</strong> – The index of the dataloader that produced this batch.
(only if multiple dataloaders used)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code> - The loss tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - A dictionary. Can include any keys, but must include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Skip to the next batch.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if you have one val dataloader:</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span> <span class="o">...</span>


<span class="c1"># if you have multiple val dataloaders:</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span> <span class="o">...</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 1: A single validation dataset</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># log 6 example images</span>
    <span class="c1"># or generated text... or whatever</span>
    <span class="n">sample_imgs</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">sample_imgs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;example_images&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;val_acc&#39;</span><span class="p">:</span> <span class="n">val_acc</span><span class="p">})</span>
</pre></div>
</div>
<p>If you pass in multiple val dataloaders, <a class="reference internal" href="#lightning_objects.LitConvNet.validation_step" title="lightning_objects.LitConvNet.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a> will have an additional argument. We recommend
setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 2: multiple validation dataloaders</span>
<span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># dataloader_idx tells you which dataset this is.</span>
    <span class="o">...</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need to validate you don’t need to implement this method.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When the <a class="reference internal" href="#lightning_objects.LitConvNet.validation_step" title="lightning_objects.LitConvNet.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a> is called, the model has been put in eval mode
and PyTorch gradients have been disabled. At the end of validation,
the model goes back to training mode and gradients are enabled.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.on_validation_epoch_end">
<span class="sig-name descname"><span class="pre">on_validation_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/lightning_objects.html#LitConvNet.on_validation_epoch_end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lightning_objects.LitConvNet.on_validation_epoch_end" title="Link to this definition">¶</a></dt>
<dd><p>Called in the validation loop at the very end of the epoch.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.on_fit_end">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/lightning_objects.html#LitConvNet.on_fit_end"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lightning_objects.LitConvNet.on_fit_end" title="Link to this definition">¶</a></dt>
<dd><p>[Custom documentation] Calls the model TrainClass’ <code class="xref py py-meth docutils literal notranslate"><span class="pre">finish_training()</span></code></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lightning_objects.LitConvNet.report">
<span class="sig-name descname"><span class="pre">report</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="_modules/lightning_objects.html#LitConvNet.report"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lightning_objects.LitConvNet.report" title="Link to this definition">¶</a></dt>
<dd><p>TODO: Could eventually add more to this. Currently just returns <code class="docutils literal notranslate"><span class="pre">self.model.report()</span></code></p>
</dd></dl>

</dd></dl>

</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="decorators.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Decorators</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="nets.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Neural Networks</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2021, Antonio Rocha
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Lightning implementation</a><ul>
<li><a class="reference internal" href="#lightning_objects.train_lightning_model"><code class="docutils literal notranslate"><span class="pre">train_lightning_model()</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.get_trainer"><code class="docutils literal notranslate"><span class="pre">get_trainer()</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet"><code class="docutils literal notranslate"><span class="pre">LitConvNet</span></code></a><ul>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.config"><code class="docutils literal notranslate"><span class="pre">LitConvNet.config</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.model_config"><code class="docutils literal notranslate"><span class="pre">LitConvNet.model_config</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.training_config"><code class="docutils literal notranslate"><span class="pre">LitConvNet.training_config</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.model"><code class="docutils literal notranslate"><span class="pre">LitConvNet.model</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.loss"><code class="docutils literal notranslate"><span class="pre">LitConvNet.loss</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.train_step_loss"><code class="docutils literal notranslate"><span class="pre">LitConvNet.train_step_loss</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.valid_step_loss"><code class="docutils literal notranslate"><span class="pre">LitConvNet.valid_step_loss</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.train_step_accur"><code class="docutils literal notranslate"><span class="pre">LitConvNet.train_step_accur</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.valid_step_accur"><code class="docutils literal notranslate"><span class="pre">LitConvNet.valid_step_accur</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.configure_optimizers"><code class="docutils literal notranslate"><span class="pre">LitConvNet.configure_optimizers()</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.forward"><code class="docutils literal notranslate"><span class="pre">LitConvNet.forward()</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.on_fit_start"><code class="docutils literal notranslate"><span class="pre">LitConvNet.on_fit_start()</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.training_step"><code class="docutils literal notranslate"><span class="pre">LitConvNet.training_step()</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.on_train_epoch_end"><code class="docutils literal notranslate"><span class="pre">LitConvNet.on_train_epoch_end()</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.validation_step"><code class="docutils literal notranslate"><span class="pre">LitConvNet.validation_step()</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.on_validation_epoch_end"><code class="docutils literal notranslate"><span class="pre">LitConvNet.on_validation_epoch_end()</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.on_fit_end"><code class="docutils literal notranslate"><span class="pre">LitConvNet.on_fit_end()</span></code></a></li>
<li><a class="reference internal" href="#lightning_objects.LitConvNet.report"><code class="docutils literal notranslate"><span class="pre">LitConvNet.report()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="_static/documentation_options.js?v=5929fcd5"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/furo.js?v=5fa4622c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>